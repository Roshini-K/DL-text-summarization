# ğŸ“ Text Summarization with Transformers

A comprehensive **text summarization system** that processes news articles and generates concise summaries using **state-of-the-art transformer models**.

---

## ğŸš€ Features

- **Data Processing**: Automated extraction and preprocessing of CNN/DailyMail dataset  
- **Transformer Models**: Support for BART, T5, and other Seq2Seq architectures  
- **Training Pipeline**: Complete training loop with validation and checkpointing  
- **Evaluation**: Comprehensive metrics including ROUGE and BLEU scores  
- **Modular Design**: Clean, maintainable code structure with proper testing  

---

## ğŸ“ Project Structure

```
text_summarization/
â”œâ”€â”€ src/ # Source code
â”‚ â”œâ”€â”€ config.py # Configuration and constants
â”‚ â”œâ”€â”€ data_loading.py # Dataset loading and extraction
â”‚ â”œâ”€â”€ preprocessing.py # Text cleaning and tokenization
â”‚ â”œâ”€â”€ model_training.py # Model initialization and training
â”‚ â”œâ”€â”€ evaluation.py # Metrics and evaluation
â”‚ â””â”€â”€ utils.py # Utility functions
â”œâ”€â”€ tests/ # Unit tests
â”‚ â”œâ”€â”€ test_data_loading.py
â”‚ â”œâ”€â”€ test_preprocessing.py
â”‚ â”œâ”€â”€ test_model_training.py
â”‚ â”œâ”€â”€ test_evaluation.py
â”‚ â””â”€â”€ test_utils.py
â”œâ”€â”€ models/ # Saved model checkpoints
â”œâ”€â”€ results/ # Evaluation results and plots
â”œâ”€â”€ experiments/ # Jupyter notebook experiments
â”œâ”€â”€ data/ # Dataset storage
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ setup.py # Package installation
â””â”€â”€ main.py # Main pipeline script
```
---

## âš™ï¸ Installation

**Clone the repository:**


```bash
git clone <your-repository-url>
cd text_summarization
```

**Create a virtual environment (recommended):**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

**Install dependencies:**

```bash
pip install -r requirements.txt
```

**Download NLTK resources (automatically handled):**

```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

## ğŸ“Š Dataset

This project uses the CNN/DailyMail dataset for training and evaluation.
The dataset will be automatically downloaded and processed when you run the pipeline.

## Run the Full Pipeline: Extract â†’ Train â†’ Evaluate
```bash
python main.py --extract --train --evaluate
```

## Run Individual Steps
**Extract dataset only**
```bash
python main.py --extract
```

**Train model only (requires extracted data)**
```bash
python main.py --train
```

**Evaluate existing model**
```bash
python main.py --evaluate
```

## ğŸ§ª Testing

Run the test suite to ensure everything works correctly:

**Run all tests**
```bash
pytest
```

**Run specific test module**
```bash
pytest tests/test_preprocessing.py -v
```

**Run with coverage report**
```bash
pytest --cov=src tests/
```

## UI Results
![Output 1](results/img1.JPG)  
![Output 2](results/img2.JPG)